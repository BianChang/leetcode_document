{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "49f70545-b995-4d95-885e-c562c1643f71",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Training a CNN with Pytorch\n",
    "We will now be using a expanded version of the digits data set to train a convolutional neural network.\n",
    "\n",
    "We will be using the Pytorch library, which is one of the main deep learning libraries. In comparison to SKlearn, Pytorch provides much more control over the architecture of your neural network, allowing you to create your own types of layers.\n",
    "\n",
    "## Import libraries, including PyTorch\n",
    "If you are using your own computer, you will need to install Pytorch. Setup guidance is here: https://pytorch.org/get-started/locally/)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "31b609b7-869f-4ebd-ad08-8e961b0fe73a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch as torch\n",
    "torch.set_num_threads(2)\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.nn as nn\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d3a012c-638d-4ec0-8771-4efb2a6bdad8",
   "metadata": {},
   "source": [
    "The next lines check if your computer has CUDA GPU capabilities and uses it if it can. Elab doesn't have available GPUs, this means that the model will still train, but it will be slower. More explanation below on what speeds you should be expecting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ebd9d008-6f39-4e37-8974-e64cb5ea1b03",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7c77cbd-c7f6-44de-b385-25c00831d5aa",
   "metadata": {},
   "source": [
    "## Import some data\n",
    "PyTorch has some built in datasets, which we will be using. We will be using the MNIST digits data set, which is a larger version of the sklearn digits dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "96a4d6df-97cd-407b-827c-7e951b9c49c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "\n",
    "train_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = True,\n",
    "    transform = ToTensor(),\n",
    "    download = True,\n",
    "    )\n",
    "    \n",
    "test_data = datasets.MNIST(\n",
    "    root = 'data',\n",
    "    train = False,\n",
    "    transform = ToTensor()\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6fa2a0ca-115c-456b-ac5d-74388faaef60",
   "metadata": {},
   "source": [
    "## View basic data set information\n",
    "Now that the dataset has been imported, you can view information about the train/test set using print(train_data) if you wish. You will see that there are 60000 training examples and 10000 test examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6ab61409-5bec-4d34-8639-c1e434d31d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset MNIST\n",
      "    Number of datapoints: 60000\n",
      "    Root location: data\n",
      "    Split: Train\n",
      "    StandardTransform\n",
      "Transform: ToTensor()\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46a43446-f966-477a-843e-234facef57fc",
   "metadata": {},
   "source": [
    "Like the Sklearn task, let's plot one of the images to see what we're looking at. Note that these are grayscale images (i.e. different shades of grey) rather than full RGB colour images. The assignment data set will contain colour images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bf8b0a09-dab4-4e36-bbd0-046e5fc18abd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaEAAAGdCAYAAAC7EMwUAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjguMywgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/H5lhTAAAACXBIWXMAAA9hAAAPYQGoP6dpAAAaxklEQVR4nO3df2xV9f3H8dcF4QrY3oxhe2+ldg2DzABhERg/wk8zGpqNCNUFdDNlMUSl4FhlbEgIHduoYwH9mgqbZEEIIiQGGQlErIEWDHZBViNBQzAUKdCmg0BvqXgR+Xz/aLjZpeXHudzbd+/t85GchHvOefe8OXxyX/1w7jnX55xzAgDAQA/rBgAA3RchBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADP3WTdws+vXr+vcuXPKyMiQz+ezbgcA4JFzTi0tLcrJyVGPHref63S5EDp37pxyc3Ot2wAA3KP6+noNHDjwtvt0uRDKyMiQ1NZ8ZmamcTcAAK/C4bByc3Oj7+e3k7QQWrdunf72t7+poaFBQ4cO1WuvvaaJEyfese7Gf8FlZmYSQgCQwu7mkkpSPpiwfft2LVq0SMuWLVNtba0mTpyowsJCnT59OhmHAwCkKF8ynqI9ZswYPfroo1q/fn103SOPPKKZM2eqvLz8trXhcFiBQEDNzc3MhAAgBXl5H0/4TOjq1as6cuSICgoKYtYXFBTo0KFD7faPRCIKh8MxCwCge0h4CJ0/f17fffedsrOzY9ZnZ2ersbGx3f7l5eUKBALRhU/GAUD3kbSbVW++IOWc6/Ai1dKlS9Xc3Bxd6uvrk9USAKCLSfin4wYMGKCePXu2m/U0NTW1mx1Jkt/vl9/vT3QbAIAUkPCZUO/evTVy5EhVVlbGrK+srNT48eMTfTgAQApLyn1CpaWleuaZZzRq1CiNGzdOb775pk6fPq3nn38+GYcDAKSopITQ7NmzdeHCBa1cuVINDQ0aNmyY9uzZo7y8vGQcDgCQopJyn9C94D4hAEhtpvcJAQBwtwghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYOY+6wYA3J36+nrPNf/3f/8X17FeffVVzzW//e1vPdf85je/8VyTm5vruQZdFzMhAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZnzOOWfdxP8Kh8MKBAJqbm5WZmamdTtAUpw9e9ZzzYgRIzzXXLp0yXNNZ/re977nuea///1vEjpBInl5H2cmBAAwQwgBAMwkPITKysrk8/lilmAwmOjDAADSQFK+1G7o0KH68MMPo6979uyZjMMAAFJcUkLovvvuY/YDALijpFwTOnHihHJycpSfn685c+bo5MmTt9w3EokoHA7HLACA7iHhITRmzBht3rxZe/fu1YYNG9TY2Kjx48frwoULHe5fXl6uQCAQXfj+eADoPpJ+n1Bra6sGDRqkJUuWqLS0tN32SCSiSCQSfR0Oh5Wbm8t9Qkhr3CfUhvuE0pOX+4SSck3of/Xr10/Dhw/XiRMnOtzu9/vl9/uT3QYAoAtK+n1CkUhEX3zxhUKhULIPBQBIMQkPocWLF6u6ulp1dXX697//rSeffFLhcFjFxcWJPhQAIMUl/L/jzpw5o6eeekrnz5/Xgw8+qLFjx6qmpkZ5eXmJPhQAIMUlPIS2bduW6B8JdGlfffWV55opU6Z4rrl48aLnGp/P57lGkgKBgOeaeK7tNjU1ea653S0ftxLvL8HcaJ98PDsOAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAmaR/qR1g4dtvv42rLp6HkU6fPt1zTX19veeazvTjH//Yc81f/vIXzzUTJkzwXDN48GDPNW+++abnGkl69tln46rD3WMmBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAww1O0kZZ+97vfxVVXUVGR4E5SU3V1teea1tZWzzWzZs3yXLNjxw7PNbW1tZ5r0DmYCQEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADDDA0zR5dXX13uu2bJlS1zHcs7FVedVPA/ufOKJJzzX/OpXv/JcI0m5ubmeax555BHPNb///e8917z77rueazrr3xXeMRMCAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABgxue62JP9wuGwAoGAmpublZmZad0OEuzs2bOea0aMGOG55tKlS55r4vXLX/7Sc82GDRs813z++eeea/7zn/94rpGkOXPmeK7p27dvXMfyqmfPnp5r+vXrF9exjh075rkmnoe/phsv7+PMhAAAZgghAIAZzyF04MABzZgxQzk5OfL5fNq5c2fMduecysrKlJOToz59+mjKlClxTWkBAOnPcwi1trZqxIgRqqio6HD76tWrtXbtWlVUVOjw4cMKBoOaNm2aWlpa7rlZAEB68fzNqoWFhSosLOxwm3NOr732mpYtW6aioiJJ0qZNm5Sdna2tW7fqueeeu7duAQBpJaHXhOrq6tTY2KiCgoLoOr/fr8mTJ+vQoUMd1kQiEYXD4ZgFANA9JDSEGhsbJUnZ2dkx67Ozs6PbblZeXq5AIBBd+HgjAHQfSfl0nM/ni3ntnGu37oalS5equbk5utTX1yejJQBAF+T5mtDtBINBSW0zolAoFF3f1NTUbnZ0g9/vl9/vT2QbAIAUkdCZUH5+voLBoCorK6Prrl69qurqao0fPz6RhwIApAHPM6HLly/ryy+/jL6uq6vTp59+qv79++vhhx/WokWLtGrVKg0ePFiDBw/WqlWr1LdvXz399NMJbRwAkPo8h9Ann3yiqVOnRl+XlpZKkoqLi/XWW29pyZIlunLliubPn6+LFy9qzJgx+uCDD5SRkZG4rgEAaYEHmCJu58+f91yzcuVKzzVvvPGG55pbXYO8k/z8fM81a9as8VwzduxYzzVoE88DTG/1wag7mT9/vuea119/Pa5jpRMeYAoASAmEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADMJ/WZVpKZr167FVbd48WLPNVu2bPFcEwgEPNfs3bvXc40k/fCHP/Rc8+2338Z1LHR9dXV11i2kPWZCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzPAAU+j06dNx1cXzMNJ41NTUeK4ZMmRIEjrpWJ8+fTrtWEC6YSYEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADOEEADADA8whUpKSuKqc855rpk1a5bnms58GCm6vuvXr3uu6dEjvt+34xnj8IaZEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADM8wDTN1NbWeq45cOBAXMfy+Xyea37xi1/EdSzghngeRhrPWJWkUaNGxVWHu8dMCABghhACAJjxHEIHDhzQjBkzlJOTI5/Pp507d8Zsnzt3rnw+X8wyduzYRPULAEgjnkOotbVVI0aMUEVFxS33mT59uhoaGqLLnj177qlJAEB68vzBhMLCQhUWFt52H7/fr2AwGHdTAIDuISnXhKqqqpSVlaUhQ4Zo3rx5ampquuW+kUhE4XA4ZgEAdA8JD6HCwkK9/fbb2rdvn9asWaPDhw/rscceUyQS6XD/8vJyBQKB6JKbm5volgAAXVTC7xOaPXt29M/Dhg3TqFGjlJeXp927d6uoqKjd/kuXLlVpaWn0dTgcJogAoJtI+s2qoVBIeXl5OnHiRIfb/X6//H5/stsAAHRBSb9P6MKFC6qvr1coFEr2oQAAKcbzTOjy5cv68ssvo6/r6ur06aefqn///urfv7/Kysr0xBNPKBQK6dSpU3r55Zc1YMAAzZo1K6GNAwBSn+cQ+uSTTzR16tTo6xvXc4qLi7V+/XodPXpUmzdv1qVLlxQKhTR16lRt375dGRkZiesaAJAWPIfQlClT5Jy75fa9e/feU0O4N998843nmlt9cvFOcnJyPNf87Gc/i+tY6PquXbvmueb1119PQiftPfnkk3HVvfzyywnuBDfj2XEAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADNJ/2ZVpK/777/fc80DDzyQhE6QaPE8EXv9+vWea5YsWeK55gc/+IHnmmXLlnmukaTevXvHVYe7x0wIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGR5girg988wz1i3gDs6ePRtX3V//+lfPNevWrfNc8+tf/9pzzYYNGzzXoOtiJgQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMDzBNM865TqmRpLfeestzzfLly+M6FqR33nnHc83ChQvjOtbFixc917z44ouea1599VXPNUgvzIQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCY4QGmacbn83VKjSSdOXPGc83KlSs91zz77LOeazIyMjzXSNKxY8c81/zjH//wXHPw4EHPNadOnfJcM2jQIM81kjRnzhzPNfE8wBRgJgQAMEMIAQDMeAqh8vJyjR49WhkZGcrKytLMmTN1/PjxmH2ccyorK1NOTo769OmjKVOmxPVfHACA9OcphKqrq1VSUqKamhpVVlbq2rVrKigoUGtra3Sf1atXa+3ataqoqNDhw4cVDAY1bdo0tbS0JLx5AEBq8/TBhPfffz/m9caNG5WVlaUjR45o0qRJcs7ptdde07Jly1RUVCRJ2rRpk7Kzs7V161Y999xziescAJDy7umaUHNzsySpf//+kqS6ujo1NjaqoKAguo/f79fkyZN16NChDn9GJBJROByOWQAA3UPcIeScU2lpqSZMmKBhw4ZJkhobGyVJ2dnZMftmZ2dHt92svLxcgUAguuTm5sbbEgAgxcQdQgsWLNBnn32md955p922m+87cc7d8l6UpUuXqrm5ObrU19fH2xIAIMXEdbPqwoULtWvXLh04cEADBw6Mrg8Gg5LaZkShUCi6vqmpqd3s6Aa/3y+/3x9PGwCAFOdpJuSc04IFC7Rjxw7t27dP+fn5Mdvz8/MVDAZVWVkZXXf16lVVV1dr/PjxiekYAJA2PM2ESkpKtHXrVv3rX/9SRkZG9DpPIBBQnz595PP5tGjRIq1atUqDBw/W4MGDtWrVKvXt21dPP/10Uv4CAIDU5SmE1q9fL0maMmVKzPqNGzdq7ty5kqQlS5boypUrmj9/vi5evKgxY8bogw8+iPtZXgCA9OVzzjnrJv5XOBxWIBBQc3OzMjMzrdtJOR9//LHnmokTJyahk8R56KGHPNfcuG3Aq6NHj8ZV1xmmT5/eKTVS2wePgHh5eR/n2XEAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMEEIAADNxfbMquq6hQ4d6rvnpT38a17E+/PDDuOq8OnPmjOeas2fPJqGTjmVlZXmueeGFFzzXLF++3HMN0NUxEwIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGB5immczMTM817777blzH2rx5s+eaF198Ma5jdZY///nPnmvmzZvnueb73/++5xogHTETAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYMbnnHPWTfyvcDisQCCg5ubmuB7GCQCw5eV9nJkQAMAMIQQAMEMIAQDMEEIAADOEEADADCEEADBDCAEAzBBCAAAzhBAAwAwhBAAwQwgBAMwQQgAAM4QQAMAMIQQAMEMIAQDMeAqh8vJyjR49WhkZGcrKytLMmTN1/PjxmH3mzp0rn88Xs4wdOzahTQMA0oOnEKqurlZJSYlqampUWVmpa9euqaCgQK2trTH7TZ8+XQ0NDdFlz549CW0aAJAe7vOy8/vvvx/zeuPGjcrKytKRI0c0adKk6Hq/369gMJiYDgEAaeuergk1NzdLkvr37x+zvqqqSllZWRoyZIjmzZunpqamW/6MSCSicDgcswAAugefc87FU+ic0+OPP66LFy/q4MGD0fXbt2/XAw88oLy8PNXV1Wn58uW6du2ajhw5Ir/f3+7nlJWV6Y9//GO79Xfz3eQAgK4nHA4rEAjc1ft43CFUUlKi3bt366OPPtLAgQNvuV9DQ4Py8vK0bds2FRUVtdseiUQUiURims/NzSWEACBFeQkhT9eEbli4cKF27dqlAwcO3DaAJCkUCikvL08nTpzocLvf7+9whgQASH+eQsg5p4ULF+q9995TVVWV8vPz71hz4cIF1dfXKxQKxd0kACA9efpgQklJibZs2aKtW7cqIyNDjY2Namxs1JUrVyRJly9f1uLFi/Xxxx/r1KlTqqqq0owZMzRgwADNmjUrKX8BAEDq8nRNyOfzdbh+48aNmjt3rq5cuaKZM2eqtrZWly5dUigU0tSpU/WnP/1Jubm5d3UML/+XCADoepJ2TehOedWnTx/t3bvXy48EAHRjPDsOAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABghhACAJghhAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGDmPusGbuackySFw2HjTgAA8bjx/n3j/fx2ulwItbS0SJJyc3ONOwEA3IuWlhYFAoHb7uNzdxNVnej69es6d+6cMjIy5PP5YraFw2Hl5uaqvr5emZmZRh3a4zy04Ty04Ty04Ty06QrnwTmnlpYW5eTkqEeP21/16XIzoR49emjgwIG33SczM7NbD7IbOA9tOA9tOA9tOA9trM/DnWZAN/DBBACAGUIIAGAmpULI7/drxYoV8vv91q2Y4jy04Ty04Ty04Ty0SbXz0OU+mAAA6D5SaiYEAEgvhBAAwAwhBAAwQwgBAMykVAitW7dO+fn5uv/++zVy5EgdPHjQuqVOVVZWJp/PF7MEg0HrtpLuwIEDmjFjhnJycuTz+bRz586Y7c45lZWVKScnR3369NGUKVN07Ngxm2aT6E7nYe7cue3Gx9ixY22aTZLy8nKNHj1aGRkZysrK0syZM3X8+PGYfbrDeLib85Aq4yFlQmj79u1atGiRli1bptraWk2cOFGFhYU6ffq0dWudaujQoWpoaIguR48etW4p6VpbWzVixAhVVFR0uH316tVau3atKioqdPjwYQWDQU2bNi36HMJ0cafzIEnTp0+PGR979uzpxA6Tr7q6WiUlJaqpqVFlZaWuXbumgoICtba2RvfpDuPhbs6DlCLjwaWIn/zkJ+7555+PWfejH/3I/eEPfzDqqPOtWLHCjRgxwroNU5Lce++9F319/fp1FwwG3SuvvBJd980337hAIOD+/ve/G3TYOW4+D845V1xc7B5//HGTfqw0NTU5Sa66uto5133Hw83nwbnUGQ8pMRO6evWqjhw5ooKCgpj1BQUFOnTokFFXNk6cOKGcnBzl5+drzpw5OnnypHVLpurq6tTY2BgzNvx+vyZPntztxoYkVVVVKSsrS0OGDNG8efPU1NRk3VJSNTc3S5L69+8vqfuOh5vPww2pMB5SIoTOnz+v7777TtnZ2THrs7Oz1djYaNRV5xszZow2b96svXv3asOGDWpsbNT48eN14cIF69bM3Pj37+5jQ5IKCwv19ttva9++fVqzZo0OHz6sxx57TJFIxLq1pHDOqbS0VBMmTNCwYcMkdc/x0NF5kFJnPHS5p2jfzs1f7eCca7cunRUWFkb/PHz4cI0bN06DBg3Spk2bVFpaatiZve4+NiRp9uzZ0T8PGzZMo0aNUl5ennbv3q2ioiLDzpJjwYIF+uyzz/TRRx+129adxsOtzkOqjIeUmAkNGDBAPXv2bPebTFNTU7vfeLqTfv36afjw4Tpx4oR1K2ZufDqQsdFeKBRSXl5eWo6PhQsXateuXdq/f3/MV790t/Fwq/PQka46HlIihHr37q2RI0eqsrIyZn1lZaXGjx9v1JW9SCSiL774QqFQyLoVM/n5+QoGgzFj4+rVq6quru7WY0OSLly4oPr6+rQaH845LViwQDt27NC+ffuUn58fs727jIc7nYeOdNnxYPihCE+2bdvmevXq5f75z3+6zz//3C1atMj169fPnTp1yrq1TvPSSy+5qqoqd/LkSVdTU+N+/vOfu4yMjLQ/By0tLa62ttbV1tY6SW7t2rWutrbWffXVV84551555RUXCATcjh073NGjR91TTz3lQqGQC4fDxp0n1u3OQ0tLi3vppZfcoUOHXF1dndu/f78bN26ce+ihh9LqPLzwwgsuEAi4qqoq19DQEF2+/vrr6D7dYTzc6Tyk0nhImRByzrk33njD5eXlud69e7tHH3005uOI3cHs2bNdKBRyvXr1cjk5Oa6oqMgdO3bMuq2k279/v5PUbikuLnbOtX0sd8WKFS4YDDq/3+8mTZrkjh49att0EtzuPHz99deuoKDAPfjgg65Xr17u4YcfdsXFxe706dPWbSdUR39/SW7jxo3RfbrDeLjTeUil8cBXOQAAzKTENSEAQHoihAAAZgghAIAZQggAYIYQAgCYIYQAAGYIIQCAGUIIAGCGEAIAmCGEAABmCCEAgBlCCABg5v8BqE1n9i1/W5EAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(train_data.data[1], cmap='Greys')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "50dd5824",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([28, 28])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data[1].size()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d2fe17f-d5ec-47b4-af1d-e792e36f3082",
   "metadata": {},
   "source": [
    "# Create the neural network architecture as a new class, CNN\n",
    "\n",
    "Defining a 'class' is beyond the scope of the course here - for a thorough introduction, read some material on Object Oriented Programming. Briefly, we can think of a 'class' as a grouping for a set of related variables and functions.\n",
    "\n",
    "The CNN class below creates the neural network architecture. Note that nn.sequential means that layers are added sequentially, so conv1 consists of a conv2d layer, a ReLU activation and a max pooling layer. Each layer type has its own parameters (in_channels, out_channels, etc.)\n",
    "\n",
    "In conv1, the convolution (conv2d) layer, we create 16 convolution filters (out_channels), a free choice by us (it can be any number). \n",
    "\n",
    "In the 2nd set of convolutions, defined by *conv2*, we have 16 convolutions from *conv1*, so our first parameter is 16 and we choose to have 32 output filters. Note that, for *conv2*, the parameters have been written in shorthand, without explicitly referring to the parameter variable name.\n",
    "\n",
    "The function, forward, describes how the whole network is put together from its component layers. It shows how we first put our input through *conv1*, then *conv2*, then *out* (a fully connected layer). "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "fb3117cd-2256-4859-9b4b-2cab285f5369",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CNN(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CNN, self).__init__()\n",
    "        self.conv1 = nn.Sequential(         \n",
    "            nn.Conv2d(\n",
    "                in_channels=1,              \n",
    "                out_channels=16,            \n",
    "                kernel_size=5,              \n",
    "                stride=1,                   \n",
    "                padding=2,                  \n",
    "            ),                              \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(kernel_size=2),    \n",
    "        )\n",
    "        self.conv2 = nn.Sequential(         \n",
    "            nn.Conv2d(16, 32, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        self.conv3 = nn.Sequential(         \n",
    "            nn.Conv2d(32, 64, 5, 1, 2),     \n",
    "            nn.ReLU(),                      \n",
    "            nn.MaxPool2d(2),                \n",
    "        )\n",
    "        # fully connected layer, output 10 classes\n",
    "        #self.out = nn.Linear(32 * 7 * 7, 10)\n",
    "        self.out = nn.Linear(64 * 3 * 3, 10)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = self.conv3(x)\n",
    "        # flatten the output of conv2 to (batch_size, 32 * 7 * 7)\n",
    "        x = x.view(x.size(0), -1)       \n",
    "        output = self.out(x)\n",
    "        return output, x    # return x for visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3180fc06-a45d-4777-ba0c-141e2b9f63f8",
   "metadata": {},
   "source": [
    "## Instantiate the neural network object\n",
    "The class code above describes what our CNN object looks like, but we need to actual create an instance of the object. We do a similar thing when we train models in sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ccf63a0e-221d-472d-afea-e6aa0b11facd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cnn = CNN() # note that the variable name can be anything here, but I've chosen cnn for clarity"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50797625-2306-4761-b571-f44c02deec45",
   "metadata": {},
   "source": [
    "# Define the loss function and optimizer \n",
    "We now define the loss function and optimizer to train the network. Unlike standard stochastic gradient descent (what we looked at in the lectures), Adam is a variant that uses an adaptive learning rate to allow for faster convergence in many situations.\n",
    "\n",
    "We set the initial learning rate at 0.01. This is quite large and may lead to non-convergence in other problems, but in this case I know it works (through trial and error), and it means that we will be able to see the impact of training in relatively few iterations\n",
    "\n",
    "We use the cross entropy loss, which is the go-to for classification problems, rather than something like the mean squared error."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "70a38e1a-7ede-458b-b4fc-974bc5ce87fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()   \n",
    "from torch import optim\n",
    "optimizer = optim.Adam(cnn.parameters(), lr = 0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1839952f-df64-438b-b5b6-9a0c2bb96528",
   "metadata": {},
   "source": [
    "# Set up training parameters\n",
    "\n",
    "Before attempting to train, we use the dataloader utility in pytorch to set up how training will work: \n",
    "the *batch_size* sets the mini-batch used in SGD (i.e. how many examples are considered at each step - in the lectures, we consider one example at a time, so-called online SGD). *shuffle* shuffles the data at each epoch, to reduce the likelihood of a weird convergence. This might happen, for instance, if all of the digits are in order, so that all of the 1s are trained first. This could lead to a situation where the network thinks that it has finished training because it sees thousands of examples of 1s, and only trains to recognise 1s. *num_workers* relates to how the data is handled in the memory (e.g. whether there are multiple sub-processes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "1ad48999-e60b-435b-8f82-efee7ad04376",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "loaders = {\n",
    "    'train' : DataLoader(train_data, \n",
    "                                          batch_size=200, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "    \n",
    "    'test'  : DataLoader(test_data, \n",
    "                                          batch_size=100, \n",
    "                                          shuffle=True, \n",
    "                                          num_workers=1),\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a1bceb8-402c-4b30-82e2-f7ac0b613fb6",
   "metadata": {},
   "source": [
    "## Training function\n",
    "We now define how model training works, over num_epochs. Note how the loss is computed. Gradients are computed using loss.backward, and then weights are updated using optimizer.step()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f730cb9f-61cd-40d6-aaaf-1efa1d1a25bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 3\n",
    "def train(num_epochs, cnn, loaders):\n",
    "    \n",
    "    # this sets the model mode - (i.e. layers like dropout, batchnorm etc behave differently during training compared to testing)\n",
    "    # note that this function was not defined explicitly in CNN, but because CNN is a type of nn.Module, it inherits some functions\n",
    "    # from the more general nn class.\n",
    "    cnn.train()\n",
    "        \n",
    "    # Train the model\n",
    "    total_step = len(loaders['train'])\n",
    "        \n",
    "    for epoch in range(num_epochs):\n",
    "        for i, (images, labels) in enumerate(loaders['train']):\n",
    "       \n",
    "            b_x = images\n",
    "            b_y = labels\n",
    "            \n",
    "            output = cnn(b_x)[0]               \n",
    "            loss = loss_func(output, b_y)\n",
    "            \n",
    "            # clear gradients for this training step   \n",
    "            optimizer.zero_grad()           \n",
    "            \n",
    "            # backpropagation, compute gradients \n",
    "            loss.backward()    \n",
    "            # apply gradients             \n",
    "            optimizer.step()                \n",
    "            \n",
    "            if (i+1) % 100 == 0:\n",
    "                print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                       .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "            pass     \n",
    "        pass\n",
    "    pass"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a58fafb8-f75e-4782-8a25-3ff8ab35a59a",
   "metadata": {},
   "source": [
    "After you have run everything above, call the training function below.\n",
    "\n",
    "**if you are running this on elab, note that it will take a *long* time to run. You may get faster results by running this on a local machine (it takese about 10 seconds on my laptop...)**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "bad724a7-f289-46a0-9b08-e33305d208d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/3], Step [100/300], Loss: 0.0398\n",
      "Epoch [1/3], Step [200/300], Loss: 0.0705\n",
      "Epoch [1/3], Step [300/300], Loss: 0.0404\n",
      "Epoch [2/3], Step [100/300], Loss: 0.0837\n",
      "Epoch [2/3], Step [200/300], Loss: 0.1120\n",
      "Epoch [2/3], Step [300/300], Loss: 0.0779\n",
      "Epoch [3/3], Step [100/300], Loss: 0.0519\n",
      "Epoch [3/3], Step [200/300], Loss: 0.0278\n",
      "Epoch [3/3], Step [300/300], Loss: 0.0224\n"
     ]
    }
   ],
   "source": [
    "train(num_epochs, cnn, loaders)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b10a4e0-2545-4c8b-9e45-663f449576b3",
   "metadata": {},
   "source": [
    "In a standard gradient descent, you would expect the training loss to go down consistently. However, we are estimating the gradient each time on a subset of the data. This means that training loss can go up as well as down - however, over enough time, it can be shown that it will converge. One of the big advantages is that SGD requires a lot less memory, as we deal with only a small number of training examples at a time."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4363c02-178f-4aa0-a7d0-27dc3587acbf",
   "metadata": {},
   "source": [
    "# Test the model\n",
    "\n",
    "Now that the model has trained, let's see how well it does...\n",
    "\n",
    "Note that the CNN model does not have a sigmoid (or softmax) activation layer - this means that the outputs are not bound between 0 and 1. If we wanted the *probability* of each class, we would need to add a softmax layer to the output. In this case, we just care about the most likely class, so we can just select the index that corresponds to the highest number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "ef73a1ab-3d70-4ad7-81f6-9f87f7cfd318",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy of the model on the 10000 test images: 0.97\n"
     ]
    }
   ],
   "source": [
    "def test():\n",
    "    # Test the model\n",
    "    cnn.eval()\n",
    "    with torch.no_grad():\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        for images, labels in loaders['test']:\n",
    "            test_output, last_layer = cnn(images) ## this runs the trained cnn. Note from the cnn class, test_output gives the model output (10 x 1 values), and last_layer gives the inputs into the last layer\n",
    "            ## torch.max finds the highest value of test_output. the [0] array element returns the maximum value, the [1] element\n",
    "            ## gives the index of that element. squeeze reshapes the data from a nx1 array into a list\n",
    "            pred_y = torch.max(test_output, 1)[1].data.squeeze() \n",
    "            #print(pred_y)\n",
    "            correct += (pred_y == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        accuracy = correct / total\n",
    "        pass\n",
    "        print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "    \n",
    "    pass\n",
    "test()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7318035-f76e-4426-b421-93d8ccb8614e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f32fde3e",
   "metadata": {},
   "source": [
    "# Changing parameters and visualize results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b95dccb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class CNN_parameter(nn.Module):\n",
    "    def __init__(self, num_conv_layers=3, dropout_rate=0.5):\n",
    "        super(CNN_parameter, self).__init__()\n",
    "        self.layer1 = nn.Sequential(\n",
    "            nn.Conv2d(1, 16, 5, 1, 2),  \n",
    "            nn.ReLU(), \n",
    "            nn.MaxPool2d(2),\n",
    "            nn.Dropout(dropout_rate)\n",
    "        )\n",
    "        if num_conv_layers > 1:\n",
    "            self.layer2 = nn.Sequential(\n",
    "                nn.Conv2d(16, 32, 5, 1, 2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "        if num_conv_layers > 2:\n",
    "            self.layer3 = nn.Sequential(\n",
    "                nn.Conv2d(32, 64, 5, 1, 2),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Dropout(dropout_rate)\n",
    "            )\n",
    "    \n",
    "        self.out = nn.Linear(64 * 3 * 3, 10) if num_conv_layers == 3 else nn.Linear(32 * 7 * 7, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.layer1(x)\n",
    "        if hasattr(self, 'layer2'):\n",
    "            x = self.layer2(x)\n",
    "        if hasattr(self, 'layer3'):\n",
    "            x = self.layer3(x)\n",
    "        x = x.view(x.size(0), -1)\n",
    "        output = self.out(x)\n",
    "        return output, x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4b8b5381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from torch import optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "\n",
    "loss_func = nn.CrossEntropyLoss()   \n",
    "def run_experiment(batch_sizes, epochs, learning_rates, dropout_rates, num_layers_list):\n",
    "    results = []\n",
    "    for batch_size in batch_sizes:\n",
    "        for num_epochs in epochs:\n",
    "            for lr in learning_rates:\n",
    "                for dropout_rate in dropout_rates:\n",
    "                    for num_layers in num_layers_list:\n",
    "                        cnn_parameter = CNN_parameter(num_conv_layers=num_layers, dropout_rate=dropout_rate)\n",
    "                        optimizer = optim.Adam(cnn_parameter.parameters(), lr=lr)\n",
    "                        loaders = {\n",
    "                            'train': DataLoader(train_data, batch_size=batch_size, shuffle=True, num_workers=1),\n",
    "                            'test': DataLoader(test_data, batch_size=batch_size, shuffle=True, num_workers=1)\n",
    "                        }\n",
    "                        #Train phase\n",
    "                        cnn_parameter.train()\n",
    "                        # Train the model\n",
    "                        total_step = len(loaders['train'])\n",
    "\n",
    "                        for epoch in range(num_epochs):\n",
    "                            for i, (images, labels) in enumerate(loaders['train']):\n",
    "\n",
    "                                b_x = images\n",
    "                                b_y = labels\n",
    "\n",
    "                                output = cnn_parameter(b_x)[0]               \n",
    "                                loss = loss_func(output, b_y)\n",
    "\n",
    "                                # clear gradients for this training step   \n",
    "                                optimizer.zero_grad()           \n",
    "                                \n",
    "                                # backpropagation, compute gradients \n",
    "                                loss.backward()    \n",
    "                                # apply gradients             \n",
    "                                optimizer.step()                \n",
    "\n",
    "                                if (i+1) % 100 == 0:\n",
    "                                    print ('Epoch [{}/{}], Step [{}/{}], Loss: {:.4f}' \n",
    "                                           .format(epoch + 1, num_epochs, i + 1, total_step, loss.item()))\n",
    "                                pass     \n",
    "                            pass\n",
    "                                          \n",
    "                        # Test phase\n",
    "                        cnn_parameter.eval()\n",
    "                        with torch.no_grad():\n",
    "                            correct = 0\n",
    "                            total = 0\n",
    "                            for images, labels in loaders['test']:\n",
    "                                test_output, last_layer = cnn_parameter(images) \n",
    "                                pred_y = torch.max(test_output, 1)[1].data.squeeze() \n",
    "                                correct += (pred_y == labels).sum().item()\n",
    "                                total += labels.size(0)\n",
    "                            accuracy = correct / total\n",
    "                                \n",
    "                            pass\n",
    "                            print('Settings: Batch Size: {}, Epochs: {}, Learning Rate: {}, Dropout Rate: {}, Layers: {}'.format(\n",
    "                            batch_size, num_epochs, lr, dropout_rate, num_layers))\n",
    "                            print('Test Accuracy of the model on the 10000 test images: %.2f' % accuracy)\n",
    "\n",
    "                        pass\n",
    "                        results.append((batch_size, num_epochs, lr, dropout_rate, num_layers, accuracy))\n",
    "                        \n",
    "    return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d9ed88d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "#import pandas as pd\n",
    "\n",
    "def plot_results(results):\n",
    "    # Convert results to a DataFrame for easier manipulation\n",
    "    df = pd.DataFrame(results, columns=['Batch Size', 'Epochs', 'Learning Rate', 'Dropout Rate', 'Number of Layers', 'Accuracy'])\n",
    "    \n",
    "    # Creating a new column 'Settings' to use as x-axis labels\n",
    "    df['Settings'] = df.apply(lambda x: f'BS:{x[\"Batch Size\"]}, Ep:{x[\"Epochs\"]}, LR:{x[\"Learning Rate\"]}, DR:{x[\"Dropout Rate\"]}, Layers:{x[\"Number of Layers\"]}', axis=1)\n",
    "    \n",
    "    # Plotting\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    bars = plt.bar(df['Settings'], df['Accuracy'], color='royalblue')\n",
    "    \n",
    "    for bar in bars:\n",
    "        yval = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2, yval + 0.005, round(yval, 2), ha='center', va='bottom', fontsize=8)\n",
    "    \n",
    "    plt.xlabel('Model Settings')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.title('Comparison of Model Accuracies Across Different Configurations')\n",
    "    plt.xticks(rotation=90)  # Rotate x-axis labels for better readability\n",
    "    plt.tight_layout()  # Adjust layout to make room for rotated x-labels\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "4278996a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/2], Step [100/1200], Loss: 0.2208\n",
      "Epoch [1/2], Step [200/1200], Loss: 0.2954\n",
      "Epoch [1/2], Step [300/1200], Loss: 0.2219\n",
      "Epoch [1/2], Step [400/1200], Loss: 0.1188\n",
      "Epoch [1/2], Step [500/1200], Loss: 0.1811\n",
      "Epoch [1/2], Step [600/1200], Loss: 0.2171\n",
      "Epoch [1/2], Step [700/1200], Loss: 0.2213\n",
      "Epoch [1/2], Step [800/1200], Loss: 0.2481\n",
      "Epoch [1/2], Step [900/1200], Loss: 0.0576\n",
      "Epoch [1/2], Step [1000/1200], Loss: 0.1586\n",
      "Epoch [1/2], Step [1100/1200], Loss: 0.0850\n",
      "Epoch [1/2], Step [1200/1200], Loss: 0.0570\n",
      "Epoch [2/2], Step [100/1200], Loss: 0.3203\n",
      "Epoch [2/2], Step [200/1200], Loss: 0.1657\n",
      "Epoch [2/2], Step [300/1200], Loss: 0.0881\n",
      "Epoch [2/2], Step [400/1200], Loss: 0.1543\n",
      "Epoch [2/2], Step [500/1200], Loss: 0.0119\n",
      "Epoch [2/2], Step [600/1200], Loss: 0.2224\n",
      "Epoch [2/2], Step [700/1200], Loss: 0.1151\n",
      "Epoch [2/2], Step [800/1200], Loss: 0.1004\n",
      "Epoch [2/2], Step [900/1200], Loss: 0.1920\n",
      "Epoch [2/2], Step [1000/1200], Loss: 0.0294\n",
      "Epoch [2/2], Step [1100/1200], Loss: 0.1330\n",
      "Epoch [2/2], Step [1200/1200], Loss: 0.2706\n",
      "Settings: Batch Size: 50, Epochs: 2, Learning Rate: 0.01, Dropout Rate: 0.1, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.98\n",
      "Epoch [1/2], Step [100/1200], Loss: 0.6517\n",
      "Epoch [1/2], Step [200/1200], Loss: 0.2398\n",
      "Epoch [1/2], Step [300/1200], Loss: 0.2170\n",
      "Epoch [1/2], Step [400/1200], Loss: 0.2252\n",
      "Epoch [1/2], Step [500/1200], Loss: 0.2139\n",
      "Epoch [1/2], Step [600/1200], Loss: 0.1834\n",
      "Epoch [1/2], Step [700/1200], Loss: 0.3579\n",
      "Epoch [1/2], Step [800/1200], Loss: 0.0909\n",
      "Epoch [1/2], Step [900/1200], Loss: 0.2597\n",
      "Epoch [1/2], Step [1000/1200], Loss: 0.4420\n",
      "Epoch [1/2], Step [1100/1200], Loss: 0.2811\n",
      "Epoch [1/2], Step [1200/1200], Loss: 0.2574\n",
      "Epoch [2/2], Step [100/1200], Loss: 0.1268\n",
      "Epoch [2/2], Step [200/1200], Loss: 0.0880\n",
      "Epoch [2/2], Step [300/1200], Loss: 0.2029\n",
      "Epoch [2/2], Step [400/1200], Loss: 0.1850\n",
      "Epoch [2/2], Step [500/1200], Loss: 0.0821\n",
      "Epoch [2/2], Step [600/1200], Loss: 0.4343\n",
      "Epoch [2/2], Step [700/1200], Loss: 0.1281\n",
      "Epoch [2/2], Step [800/1200], Loss: 0.2457\n",
      "Epoch [2/2], Step [900/1200], Loss: 0.2001\n",
      "Epoch [2/2], Step [1000/1200], Loss: 0.1839\n",
      "Epoch [2/2], Step [1100/1200], Loss: 0.2350\n",
      "Epoch [2/2], Step [1200/1200], Loss: 0.1691\n",
      "Settings: Batch Size: 50, Epochs: 2, Learning Rate: 0.01, Dropout Rate: 0.1, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.96\n",
      "Epoch [1/2], Step [100/1200], Loss: 0.6322\n",
      "Epoch [1/2], Step [200/1200], Loss: 0.1832\n",
      "Epoch [1/2], Step [300/1200], Loss: 0.2929\n",
      "Epoch [1/2], Step [400/1200], Loss: 0.2825\n",
      "Epoch [1/2], Step [500/1200], Loss: 0.0647\n",
      "Epoch [1/2], Step [600/1200], Loss: 0.1136\n",
      "Epoch [1/2], Step [700/1200], Loss: 0.3516\n",
      "Epoch [1/2], Step [800/1200], Loss: 0.1134\n",
      "Epoch [1/2], Step [900/1200], Loss: 0.0940\n",
      "Epoch [1/2], Step [1000/1200], Loss: 0.0618\n",
      "Epoch [1/2], Step [1100/1200], Loss: 0.1505\n",
      "Epoch [1/2], Step [1200/1200], Loss: 0.0847\n",
      "Epoch [2/2], Step [100/1200], Loss: 0.0776\n",
      "Epoch [2/2], Step [200/1200], Loss: 0.2082\n",
      "Epoch [2/2], Step [300/1200], Loss: 0.0562\n",
      "Epoch [2/2], Step [400/1200], Loss: 0.0303\n",
      "Epoch [2/2], Step [500/1200], Loss: 0.0422\n",
      "Epoch [2/2], Step [600/1200], Loss: 0.2239\n",
      "Epoch [2/2], Step [700/1200], Loss: 0.0429\n",
      "Epoch [2/2], Step [800/1200], Loss: 0.1386\n",
      "Epoch [2/2], Step [900/1200], Loss: 0.1397\n",
      "Epoch [2/2], Step [1000/1200], Loss: 0.0541\n",
      "Epoch [2/2], Step [1100/1200], Loss: 0.0626\n",
      "Epoch [2/2], Step [1200/1200], Loss: 0.1634\n",
      "Settings: Batch Size: 50, Epochs: 2, Learning Rate: 0.01, Dropout Rate: 0.2, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.98\n",
      "Epoch [1/2], Step [100/1200], Loss: 2.3059\n",
      "Epoch [1/2], Step [200/1200], Loss: 2.2918\n",
      "Epoch [1/2], Step [300/1200], Loss: 2.3116\n",
      "Epoch [1/2], Step [400/1200], Loss: 2.2947\n",
      "Epoch [1/2], Step [500/1200], Loss: 2.3078\n",
      "Epoch [1/2], Step [600/1200], Loss: 2.2971\n",
      "Epoch [1/2], Step [700/1200], Loss: 2.3193\n",
      "Epoch [1/2], Step [800/1200], Loss: 2.3130\n",
      "Epoch [1/2], Step [900/1200], Loss: 2.2995\n",
      "Epoch [1/2], Step [1000/1200], Loss: 2.3134\n",
      "Epoch [1/2], Step [1100/1200], Loss: 2.2950\n",
      "Epoch [1/2], Step [1200/1200], Loss: 2.2943\n",
      "Epoch [2/2], Step [100/1200], Loss: 2.2910\n",
      "Epoch [2/2], Step [200/1200], Loss: 2.3107\n",
      "Epoch [2/2], Step [300/1200], Loss: 2.2792\n",
      "Epoch [2/2], Step [400/1200], Loss: 2.3065\n",
      "Epoch [2/2], Step [500/1200], Loss: 2.3089\n",
      "Epoch [2/2], Step [600/1200], Loss: 2.3083\n",
      "Epoch [2/2], Step [700/1200], Loss: 2.2974\n",
      "Epoch [2/2], Step [800/1200], Loss: 2.3105\n",
      "Epoch [2/2], Step [900/1200], Loss: 2.3069\n",
      "Epoch [2/2], Step [1000/1200], Loss: 2.3077\n",
      "Epoch [2/2], Step [1100/1200], Loss: 2.3080\n",
      "Epoch [2/2], Step [1200/1200], Loss: 2.3121\n",
      "Settings: Batch Size: 50, Epochs: 2, Learning Rate: 0.01, Dropout Rate: 0.2, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.11\n",
      "Epoch [1/2], Step [100/1200], Loss: 0.5489\n",
      "Epoch [1/2], Step [200/1200], Loss: 0.1455\n",
      "Epoch [1/2], Step [300/1200], Loss: 0.0941\n",
      "Epoch [1/2], Step [400/1200], Loss: 0.3448\n",
      "Epoch [1/2], Step [500/1200], Loss: 0.0920\n",
      "Epoch [1/2], Step [600/1200], Loss: 0.0889\n",
      "Epoch [1/2], Step [700/1200], Loss: 0.0802\n",
      "Epoch [1/2], Step [800/1200], Loss: 0.1406\n",
      "Epoch [1/2], Step [900/1200], Loss: 0.0828\n",
      "Epoch [1/2], Step [1000/1200], Loss: 0.2680\n",
      "Epoch [1/2], Step [1100/1200], Loss: 0.0444\n",
      "Epoch [1/2], Step [1200/1200], Loss: 0.1255\n",
      "Epoch [2/2], Step [100/1200], Loss: 0.0403\n",
      "Epoch [2/2], Step [200/1200], Loss: 0.0143\n",
      "Epoch [2/2], Step [300/1200], Loss: 0.0887\n",
      "Epoch [2/2], Step [400/1200], Loss: 0.0358\n",
      "Epoch [2/2], Step [500/1200], Loss: 0.0240\n",
      "Epoch [2/2], Step [600/1200], Loss: 0.3287\n",
      "Epoch [2/2], Step [700/1200], Loss: 0.0489\n",
      "Epoch [2/2], Step [800/1200], Loss: 0.0993\n",
      "Epoch [2/2], Step [900/1200], Loss: 0.0331\n",
      "Epoch [2/2], Step [1000/1200], Loss: 0.0513\n",
      "Epoch [2/2], Step [1100/1200], Loss: 0.0341\n",
      "Epoch [2/2], Step [1200/1200], Loss: 0.0088\n",
      "Settings: Batch Size: 50, Epochs: 2, Learning Rate: 0.001, Dropout Rate: 0.1, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/2], Step [100/1200], Loss: 0.5238\n",
      "Epoch [1/2], Step [200/1200], Loss: 0.3374\n",
      "Epoch [1/2], Step [300/1200], Loss: 0.1124\n",
      "Epoch [1/2], Step [400/1200], Loss: 0.1928\n",
      "Epoch [1/2], Step [500/1200], Loss: 0.1203\n",
      "Epoch [1/2], Step [600/1200], Loss: 0.0962\n",
      "Epoch [1/2], Step [700/1200], Loss: 0.0650\n",
      "Epoch [1/2], Step [800/1200], Loss: 0.0332\n",
      "Epoch [1/2], Step [900/1200], Loss: 0.0231\n",
      "Epoch [1/2], Step [1000/1200], Loss: 0.0380\n",
      "Epoch [1/2], Step [1100/1200], Loss: 0.1270\n",
      "Epoch [1/2], Step [1200/1200], Loss: 0.0122\n",
      "Epoch [2/2], Step [100/1200], Loss: 0.0467\n",
      "Epoch [2/2], Step [200/1200], Loss: 0.0387\n",
      "Epoch [2/2], Step [300/1200], Loss: 0.0456\n",
      "Epoch [2/2], Step [400/1200], Loss: 0.0390\n",
      "Epoch [2/2], Step [500/1200], Loss: 0.2074\n",
      "Epoch [2/2], Step [600/1200], Loss: 0.0394\n",
      "Epoch [2/2], Step [700/1200], Loss: 0.0594\n",
      "Epoch [2/2], Step [800/1200], Loss: 0.0783\n",
      "Epoch [2/2], Step [900/1200], Loss: 0.1009\n",
      "Epoch [2/2], Step [1000/1200], Loss: 0.0129\n",
      "Epoch [2/2], Step [1100/1200], Loss: 0.0339\n",
      "Epoch [2/2], Step [1200/1200], Loss: 0.2952\n",
      "Settings: Batch Size: 50, Epochs: 2, Learning Rate: 0.001, Dropout Rate: 0.1, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/2], Step [100/1200], Loss: 0.6305\n",
      "Epoch [1/2], Step [200/1200], Loss: 0.2954\n",
      "Epoch [1/2], Step [300/1200], Loss: 0.3723\n",
      "Epoch [1/2], Step [400/1200], Loss: 0.0792\n",
      "Epoch [1/2], Step [500/1200], Loss: 0.2941\n",
      "Epoch [1/2], Step [600/1200], Loss: 0.0641\n",
      "Epoch [1/2], Step [700/1200], Loss: 0.1078\n",
      "Epoch [1/2], Step [800/1200], Loss: 0.0958\n",
      "Epoch [1/2], Step [900/1200], Loss: 0.0608\n",
      "Epoch [1/2], Step [1000/1200], Loss: 0.2321\n",
      "Epoch [1/2], Step [1100/1200], Loss: 0.0272\n",
      "Epoch [1/2], Step [1200/1200], Loss: 0.2776\n",
      "Epoch [2/2], Step [100/1200], Loss: 0.0726\n",
      "Epoch [2/2], Step [200/1200], Loss: 0.0599\n",
      "Epoch [2/2], Step [300/1200], Loss: 0.1925\n",
      "Epoch [2/2], Step [400/1200], Loss: 0.0751\n",
      "Epoch [2/2], Step [500/1200], Loss: 0.0467\n",
      "Epoch [2/2], Step [600/1200], Loss: 0.0581\n",
      "Epoch [2/2], Step [700/1200], Loss: 0.0297\n",
      "Epoch [2/2], Step [800/1200], Loss: 0.0141\n",
      "Epoch [2/2], Step [900/1200], Loss: 0.0510\n",
      "Epoch [2/2], Step [1000/1200], Loss: 0.0097\n",
      "Epoch [2/2], Step [1100/1200], Loss: 0.0212\n",
      "Epoch [2/2], Step [1200/1200], Loss: 0.1124\n",
      "Settings: Batch Size: 50, Epochs: 2, Learning Rate: 0.001, Dropout Rate: 0.2, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/2], Step [100/1200], Loss: 0.4711\n",
      "Epoch [1/2], Step [200/1200], Loss: 0.2209\n",
      "Epoch [1/2], Step [300/1200], Loss: 0.1808\n",
      "Epoch [1/2], Step [400/1200], Loss: 0.2523\n",
      "Epoch [1/2], Step [500/1200], Loss: 0.0657\n",
      "Epoch [1/2], Step [600/1200], Loss: 0.0386\n",
      "Epoch [1/2], Step [700/1200], Loss: 0.1490\n",
      "Epoch [1/2], Step [800/1200], Loss: 0.0309\n",
      "Epoch [1/2], Step [900/1200], Loss: 0.1272\n",
      "Epoch [1/2], Step [1000/1200], Loss: 0.1857\n",
      "Epoch [1/2], Step [1100/1200], Loss: 0.0961\n",
      "Epoch [1/2], Step [1200/1200], Loss: 0.6834\n",
      "Epoch [2/2], Step [100/1200], Loss: 0.0129\n",
      "Epoch [2/2], Step [200/1200], Loss: 0.2029\n",
      "Epoch [2/2], Step [300/1200], Loss: 0.0290\n",
      "Epoch [2/2], Step [400/1200], Loss: 0.1219\n",
      "Epoch [2/2], Step [500/1200], Loss: 0.1007\n",
      "Epoch [2/2], Step [600/1200], Loss: 0.0902\n",
      "Epoch [2/2], Step [700/1200], Loss: 0.0068\n",
      "Epoch [2/2], Step [800/1200], Loss: 0.0075\n",
      "Epoch [2/2], Step [900/1200], Loss: 0.0540\n",
      "Epoch [2/2], Step [1000/1200], Loss: 0.0422\n",
      "Epoch [2/2], Step [1100/1200], Loss: 0.0044\n",
      "Epoch [2/2], Step [1200/1200], Loss: 0.0816\n",
      "Settings: Batch Size: 50, Epochs: 2, Learning Rate: 0.001, Dropout Rate: 0.2, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/3], Step [100/1200], Loss: 0.2264\n",
      "Epoch [1/3], Step [200/1200], Loss: 0.1874\n",
      "Epoch [1/3], Step [300/1200], Loss: 0.0478\n",
      "Epoch [1/3], Step [400/1200], Loss: 0.0751\n",
      "Epoch [1/3], Step [500/1200], Loss: 0.0977\n",
      "Epoch [1/3], Step [600/1200], Loss: 0.1433\n",
      "Epoch [1/3], Step [700/1200], Loss: 0.1196\n",
      "Epoch [1/3], Step [800/1200], Loss: 0.1160\n",
      "Epoch [1/3], Step [900/1200], Loss: 0.0080\n",
      "Epoch [1/3], Step [1000/1200], Loss: 0.1625\n",
      "Epoch [1/3], Step [1100/1200], Loss: 0.0902\n",
      "Epoch [1/3], Step [1200/1200], Loss: 0.0603\n",
      "Epoch [2/3], Step [100/1200], Loss: 0.0399\n",
      "Epoch [2/3], Step [200/1200], Loss: 0.0348\n",
      "Epoch [2/3], Step [300/1200], Loss: 0.0079\n",
      "Epoch [2/3], Step [400/1200], Loss: 0.0186\n",
      "Epoch [2/3], Step [500/1200], Loss: 0.0592\n",
      "Epoch [2/3], Step [600/1200], Loss: 0.0220\n",
      "Epoch [2/3], Step [700/1200], Loss: 0.1701\n",
      "Epoch [2/3], Step [800/1200], Loss: 0.4068\n",
      "Epoch [2/3], Step [900/1200], Loss: 0.0672\n",
      "Epoch [2/3], Step [1000/1200], Loss: 0.0638\n",
      "Epoch [2/3], Step [1100/1200], Loss: 0.1814\n",
      "Epoch [2/3], Step [1200/1200], Loss: 0.0018\n",
      "Epoch [3/3], Step [100/1200], Loss: 0.0104\n",
      "Epoch [3/3], Step [200/1200], Loss: 0.0207\n",
      "Epoch [3/3], Step [300/1200], Loss: 0.0132\n",
      "Epoch [3/3], Step [400/1200], Loss: 0.0393\n",
      "Epoch [3/3], Step [500/1200], Loss: 0.0832\n",
      "Epoch [3/3], Step [600/1200], Loss: 0.0008\n",
      "Epoch [3/3], Step [700/1200], Loss: 0.2202\n",
      "Epoch [3/3], Step [800/1200], Loss: 0.0108\n",
      "Epoch [3/3], Step [900/1200], Loss: 0.0251\n",
      "Epoch [3/3], Step [1000/1200], Loss: 0.0817\n",
      "Epoch [3/3], Step [1100/1200], Loss: 0.1689\n",
      "Epoch [3/3], Step [1200/1200], Loss: 0.0017\n",
      "Settings: Batch Size: 50, Epochs: 3, Learning Rate: 0.01, Dropout Rate: 0.1, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.98\n",
      "Epoch [1/3], Step [100/1200], Loss: 2.2730\n",
      "Epoch [1/3], Step [200/1200], Loss: 2.3158\n",
      "Epoch [1/3], Step [300/1200], Loss: 2.3046\n",
      "Epoch [1/3], Step [400/1200], Loss: 2.2953\n",
      "Epoch [1/3], Step [500/1200], Loss: 2.2963\n",
      "Epoch [1/3], Step [600/1200], Loss: 2.3208\n",
      "Epoch [1/3], Step [700/1200], Loss: 2.3082\n",
      "Epoch [1/3], Step [800/1200], Loss: 2.2836\n",
      "Epoch [1/3], Step [900/1200], Loss: 2.3023\n",
      "Epoch [1/3], Step [1000/1200], Loss: 2.2947\n",
      "Epoch [1/3], Step [1100/1200], Loss: 2.2847\n",
      "Epoch [1/3], Step [1200/1200], Loss: 2.3095\n",
      "Epoch [2/3], Step [100/1200], Loss: 2.2891\n",
      "Epoch [2/3], Step [200/1200], Loss: 2.3069\n",
      "Epoch [2/3], Step [300/1200], Loss: 2.2886\n",
      "Epoch [2/3], Step [400/1200], Loss: 2.3048\n",
      "Epoch [2/3], Step [500/1200], Loss: 2.3135\n",
      "Epoch [2/3], Step [600/1200], Loss: 2.3118\n",
      "Epoch [2/3], Step [700/1200], Loss: 2.2946\n",
      "Epoch [2/3], Step [800/1200], Loss: 2.3064\n",
      "Epoch [2/3], Step [900/1200], Loss: 2.2908\n",
      "Epoch [2/3], Step [1000/1200], Loss: 2.3041\n",
      "Epoch [2/3], Step [1100/1200], Loss: 2.3000\n",
      "Epoch [2/3], Step [1200/1200], Loss: 2.3092\n",
      "Epoch [3/3], Step [100/1200], Loss: 2.3082\n",
      "Epoch [3/3], Step [200/1200], Loss: 2.3210\n",
      "Epoch [3/3], Step [300/1200], Loss: 2.3034\n",
      "Epoch [3/3], Step [400/1200], Loss: 2.2968\n",
      "Epoch [3/3], Step [500/1200], Loss: 2.3046\n",
      "Epoch [3/3], Step [600/1200], Loss: 2.2959\n",
      "Epoch [3/3], Step [700/1200], Loss: 2.2991\n",
      "Epoch [3/3], Step [800/1200], Loss: 2.2877\n",
      "Epoch [3/3], Step [900/1200], Loss: 2.2911\n",
      "Epoch [3/3], Step [1000/1200], Loss: 2.2970\n",
      "Epoch [3/3], Step [1100/1200], Loss: 2.2958\n",
      "Epoch [3/3], Step [1200/1200], Loss: 2.3021\n",
      "Settings: Batch Size: 50, Epochs: 3, Learning Rate: 0.01, Dropout Rate: 0.1, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.11\n",
      "Epoch [1/3], Step [100/1200], Loss: 0.3797\n",
      "Epoch [1/3], Step [200/1200], Loss: 0.1848\n",
      "Epoch [1/3], Step [300/1200], Loss: 0.0542\n",
      "Epoch [1/3], Step [400/1200], Loss: 0.0648\n",
      "Epoch [1/3], Step [500/1200], Loss: 0.1029\n",
      "Epoch [1/3], Step [600/1200], Loss: 0.1225\n",
      "Epoch [1/3], Step [700/1200], Loss: 0.0486\n",
      "Epoch [1/3], Step [800/1200], Loss: 0.1073\n",
      "Epoch [1/3], Step [900/1200], Loss: 0.1647\n",
      "Epoch [1/3], Step [1000/1200], Loss: 0.0624\n",
      "Epoch [1/3], Step [1100/1200], Loss: 0.2139\n",
      "Epoch [1/3], Step [1200/1200], Loss: 0.0169\n",
      "Epoch [2/3], Step [100/1200], Loss: 0.2004\n",
      "Epoch [2/3], Step [200/1200], Loss: 0.2174\n",
      "Epoch [2/3], Step [300/1200], Loss: 0.0360\n",
      "Epoch [2/3], Step [400/1200], Loss: 0.0813\n",
      "Epoch [2/3], Step [500/1200], Loss: 0.1874\n",
      "Epoch [2/3], Step [600/1200], Loss: 0.0596\n",
      "Epoch [2/3], Step [700/1200], Loss: 0.0420\n",
      "Epoch [2/3], Step [800/1200], Loss: 0.1414\n",
      "Epoch [2/3], Step [900/1200], Loss: 0.0254\n",
      "Epoch [2/3], Step [1000/1200], Loss: 0.1133\n",
      "Epoch [2/3], Step [1100/1200], Loss: 0.1105\n",
      "Epoch [2/3], Step [1200/1200], Loss: 0.1483\n",
      "Epoch [3/3], Step [100/1200], Loss: 0.0488\n",
      "Epoch [3/3], Step [200/1200], Loss: 0.1589\n",
      "Epoch [3/3], Step [300/1200], Loss: 0.1677\n",
      "Epoch [3/3], Step [400/1200], Loss: 0.0736\n",
      "Epoch [3/3], Step [500/1200], Loss: 0.1506\n",
      "Epoch [3/3], Step [600/1200], Loss: 0.0634\n",
      "Epoch [3/3], Step [700/1200], Loss: 0.0077\n",
      "Epoch [3/3], Step [800/1200], Loss: 0.1252\n",
      "Epoch [3/3], Step [900/1200], Loss: 0.1016\n",
      "Epoch [3/3], Step [1000/1200], Loss: 0.2051\n",
      "Epoch [3/3], Step [1100/1200], Loss: 0.0697\n",
      "Epoch [3/3], Step [1200/1200], Loss: 0.2059\n",
      "Settings: Batch Size: 50, Epochs: 3, Learning Rate: 0.01, Dropout Rate: 0.2, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.98\n",
      "Epoch [1/3], Step [100/1200], Loss: 2.2963\n",
      "Epoch [1/3], Step [200/1200], Loss: 2.2946\n",
      "Epoch [1/3], Step [300/1200], Loss: 2.2982\n",
      "Epoch [1/3], Step [400/1200], Loss: 2.3021\n",
      "Epoch [1/3], Step [500/1200], Loss: 2.3111\n",
      "Epoch [1/3], Step [600/1200], Loss: 2.3015\n",
      "Epoch [1/3], Step [700/1200], Loss: 2.3022\n",
      "Epoch [1/3], Step [800/1200], Loss: 2.3047\n",
      "Epoch [1/3], Step [900/1200], Loss: 2.3050\n",
      "Epoch [1/3], Step [1000/1200], Loss: 2.3076\n",
      "Epoch [1/3], Step [1100/1200], Loss: 2.2969\n",
      "Epoch [1/3], Step [1200/1200], Loss: 2.2873\n",
      "Epoch [2/3], Step [100/1200], Loss: 2.2897\n",
      "Epoch [2/3], Step [200/1200], Loss: 2.3143\n",
      "Epoch [2/3], Step [300/1200], Loss: 2.2943\n",
      "Epoch [2/3], Step [400/1200], Loss: 2.2896\n",
      "Epoch [2/3], Step [500/1200], Loss: 2.3073\n",
      "Epoch [2/3], Step [600/1200], Loss: 2.3064\n",
      "Epoch [2/3], Step [700/1200], Loss: 2.2960\n",
      "Epoch [2/3], Step [800/1200], Loss: 2.2995\n",
      "Epoch [2/3], Step [900/1200], Loss: 2.3014\n",
      "Epoch [2/3], Step [1000/1200], Loss: 2.3063\n",
      "Epoch [2/3], Step [1100/1200], Loss: 2.2918\n",
      "Epoch [2/3], Step [1200/1200], Loss: 2.2988\n",
      "Epoch [3/3], Step [100/1200], Loss: 2.2998\n",
      "Epoch [3/3], Step [200/1200], Loss: 2.2954\n",
      "Epoch [3/3], Step [300/1200], Loss: 2.2978\n",
      "Epoch [3/3], Step [400/1200], Loss: 2.3085\n",
      "Epoch [3/3], Step [500/1200], Loss: 2.3077\n",
      "Epoch [3/3], Step [600/1200], Loss: 2.2953\n",
      "Epoch [3/3], Step [700/1200], Loss: 2.3041\n",
      "Epoch [3/3], Step [800/1200], Loss: 2.2906\n",
      "Epoch [3/3], Step [900/1200], Loss: 2.3013\n",
      "Epoch [3/3], Step [1000/1200], Loss: 2.3203\n",
      "Epoch [3/3], Step [1100/1200], Loss: 2.3082\n",
      "Epoch [3/3], Step [1200/1200], Loss: 2.3128\n",
      "Settings: Batch Size: 50, Epochs: 3, Learning Rate: 0.01, Dropout Rate: 0.2, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.11\n",
      "Epoch [1/3], Step [100/1200], Loss: 0.5990\n",
      "Epoch [1/3], Step [200/1200], Loss: 0.1785\n",
      "Epoch [1/3], Step [300/1200], Loss: 0.0416\n",
      "Epoch [1/3], Step [400/1200], Loss: 0.1974\n",
      "Epoch [1/3], Step [500/1200], Loss: 0.4102\n",
      "Epoch [1/3], Step [600/1200], Loss: 0.0936\n",
      "Epoch [1/3], Step [700/1200], Loss: 0.1435\n",
      "Epoch [1/3], Step [800/1200], Loss: 0.1045\n",
      "Epoch [1/3], Step [900/1200], Loss: 0.0977\n",
      "Epoch [1/3], Step [1000/1200], Loss: 0.2024\n",
      "Epoch [1/3], Step [1100/1200], Loss: 0.1105\n",
      "Epoch [1/3], Step [1200/1200], Loss: 0.1542\n",
      "Epoch [2/3], Step [100/1200], Loss: 0.0464\n",
      "Epoch [2/3], Step [200/1200], Loss: 0.0345\n",
      "Epoch [2/3], Step [300/1200], Loss: 0.1051\n",
      "Epoch [2/3], Step [400/1200], Loss: 0.0727\n",
      "Epoch [2/3], Step [500/1200], Loss: 0.0447\n",
      "Epoch [2/3], Step [600/1200], Loss: 0.0357\n",
      "Epoch [2/3], Step [700/1200], Loss: 0.1265\n",
      "Epoch [2/3], Step [800/1200], Loss: 0.0448\n",
      "Epoch [2/3], Step [900/1200], Loss: 0.0411\n",
      "Epoch [2/3], Step [1000/1200], Loss: 0.0286\n",
      "Epoch [2/3], Step [1100/1200], Loss: 0.0416\n",
      "Epoch [2/3], Step [1200/1200], Loss: 0.1419\n",
      "Epoch [3/3], Step [100/1200], Loss: 0.0107\n",
      "Epoch [3/3], Step [200/1200], Loss: 0.0270\n",
      "Epoch [3/3], Step [300/1200], Loss: 0.0079\n",
      "Epoch [3/3], Step [400/1200], Loss: 0.0505\n",
      "Epoch [3/3], Step [500/1200], Loss: 0.0397\n",
      "Epoch [3/3], Step [600/1200], Loss: 0.0996\n",
      "Epoch [3/3], Step [700/1200], Loss: 0.0644\n",
      "Epoch [3/3], Step [800/1200], Loss: 0.0442\n",
      "Epoch [3/3], Step [900/1200], Loss: 0.0144\n",
      "Epoch [3/3], Step [1000/1200], Loss: 0.0084\n",
      "Epoch [3/3], Step [1100/1200], Loss: 0.0021\n",
      "Epoch [3/3], Step [1200/1200], Loss: 0.0036\n",
      "Settings: Batch Size: 50, Epochs: 3, Learning Rate: 0.001, Dropout Rate: 0.1, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/3], Step [100/1200], Loss: 0.5276\n",
      "Epoch [1/3], Step [200/1200], Loss: 0.2039\n",
      "Epoch [1/3], Step [300/1200], Loss: 0.1293\n",
      "Epoch [1/3], Step [400/1200], Loss: 0.1683\n",
      "Epoch [1/3], Step [500/1200], Loss: 0.0450\n",
      "Epoch [1/3], Step [600/1200], Loss: 0.3774\n",
      "Epoch [1/3], Step [700/1200], Loss: 0.1799\n",
      "Epoch [1/3], Step [800/1200], Loss: 0.0349\n",
      "Epoch [1/3], Step [900/1200], Loss: 0.0531\n",
      "Epoch [1/3], Step [1000/1200], Loss: 0.0403\n",
      "Epoch [1/3], Step [1100/1200], Loss: 0.0571\n",
      "Epoch [1/3], Step [1200/1200], Loss: 0.0632\n",
      "Epoch [2/3], Step [100/1200], Loss: 0.0144\n",
      "Epoch [2/3], Step [200/1200], Loss: 0.1175\n",
      "Epoch [2/3], Step [300/1200], Loss: 0.0129\n",
      "Epoch [2/3], Step [400/1200], Loss: 0.1063\n",
      "Epoch [2/3], Step [500/1200], Loss: 0.0920\n",
      "Epoch [2/3], Step [600/1200], Loss: 0.0360\n",
      "Epoch [2/3], Step [700/1200], Loss: 0.0049\n",
      "Epoch [2/3], Step [800/1200], Loss: 0.1364\n",
      "Epoch [2/3], Step [900/1200], Loss: 0.0226\n",
      "Epoch [2/3], Step [1000/1200], Loss: 0.0367\n",
      "Epoch [2/3], Step [1100/1200], Loss: 0.0126\n",
      "Epoch [2/3], Step [1200/1200], Loss: 0.0356\n",
      "Epoch [3/3], Step [100/1200], Loss: 0.0717\n",
      "Epoch [3/3], Step [200/1200], Loss: 0.0061\n",
      "Epoch [3/3], Step [300/1200], Loss: 0.0320\n",
      "Epoch [3/3], Step [400/1200], Loss: 0.0076\n",
      "Epoch [3/3], Step [500/1200], Loss: 0.1084\n",
      "Epoch [3/3], Step [600/1200], Loss: 0.0526\n",
      "Epoch [3/3], Step [700/1200], Loss: 0.0045\n",
      "Epoch [3/3], Step [800/1200], Loss: 0.0765\n",
      "Epoch [3/3], Step [900/1200], Loss: 0.0152\n",
      "Epoch [3/3], Step [1000/1200], Loss: 0.0161\n",
      "Epoch [3/3], Step [1100/1200], Loss: 0.0556\n",
      "Epoch [3/3], Step [1200/1200], Loss: 0.1065\n",
      "Settings: Batch Size: 50, Epochs: 3, Learning Rate: 0.001, Dropout Rate: 0.1, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/3], Step [100/1200], Loss: 0.4796\n",
      "Epoch [1/3], Step [200/1200], Loss: 0.1002\n",
      "Epoch [1/3], Step [300/1200], Loss: 0.0804\n",
      "Epoch [1/3], Step [400/1200], Loss: 0.0897\n",
      "Epoch [1/3], Step [500/1200], Loss: 0.0528\n",
      "Epoch [1/3], Step [600/1200], Loss: 0.0645\n",
      "Epoch [1/3], Step [700/1200], Loss: 0.0939\n",
      "Epoch [1/3], Step [800/1200], Loss: 0.0680\n",
      "Epoch [1/3], Step [900/1200], Loss: 0.1691\n",
      "Epoch [1/3], Step [1000/1200], Loss: 0.0500\n",
      "Epoch [1/3], Step [1100/1200], Loss: 0.0816\n",
      "Epoch [1/3], Step [1200/1200], Loss: 0.0615\n",
      "Epoch [2/3], Step [100/1200], Loss: 0.0368\n",
      "Epoch [2/3], Step [200/1200], Loss: 0.0082\n",
      "Epoch [2/3], Step [300/1200], Loss: 0.0365\n",
      "Epoch [2/3], Step [400/1200], Loss: 0.0665\n",
      "Epoch [2/3], Step [500/1200], Loss: 0.0116\n",
      "Epoch [2/3], Step [600/1200], Loss: 0.1033\n",
      "Epoch [2/3], Step [700/1200], Loss: 0.0180\n",
      "Epoch [2/3], Step [800/1200], Loss: 0.0503\n",
      "Epoch [2/3], Step [900/1200], Loss: 0.0307\n",
      "Epoch [2/3], Step [1000/1200], Loss: 0.0245\n",
      "Epoch [2/3], Step [1100/1200], Loss: 0.0341\n",
      "Epoch [2/3], Step [1200/1200], Loss: 0.0295\n",
      "Epoch [3/3], Step [100/1200], Loss: 0.1320\n",
      "Epoch [3/3], Step [200/1200], Loss: 0.0841\n",
      "Epoch [3/3], Step [300/1200], Loss: 0.0500\n",
      "Epoch [3/3], Step [400/1200], Loss: 0.0165\n",
      "Epoch [3/3], Step [500/1200], Loss: 0.0581\n",
      "Epoch [3/3], Step [600/1200], Loss: 0.0425\n",
      "Epoch [3/3], Step [700/1200], Loss: 0.0227\n",
      "Epoch [3/3], Step [800/1200], Loss: 0.1088\n",
      "Epoch [3/3], Step [900/1200], Loss: 0.0342\n",
      "Epoch [3/3], Step [1000/1200], Loss: 0.0172\n",
      "Epoch [3/3], Step [1100/1200], Loss: 0.0051\n",
      "Epoch [3/3], Step [1200/1200], Loss: 0.1322\n",
      "Settings: Batch Size: 50, Epochs: 3, Learning Rate: 0.001, Dropout Rate: 0.2, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/3], Step [100/1200], Loss: 0.6309\n",
      "Epoch [1/3], Step [200/1200], Loss: 0.1716\n",
      "Epoch [1/3], Step [300/1200], Loss: 0.2942\n",
      "Epoch [1/3], Step [400/1200], Loss: 0.0622\n",
      "Epoch [1/3], Step [500/1200], Loss: 0.0374\n",
      "Epoch [1/3], Step [600/1200], Loss: 0.0374\n",
      "Epoch [1/3], Step [700/1200], Loss: 0.0644\n",
      "Epoch [1/3], Step [800/1200], Loss: 0.1542\n",
      "Epoch [1/3], Step [900/1200], Loss: 0.2317\n",
      "Epoch [1/3], Step [1000/1200], Loss: 0.1434\n",
      "Epoch [1/3], Step [1100/1200], Loss: 0.1911\n",
      "Epoch [1/3], Step [1200/1200], Loss: 0.0723\n",
      "Epoch [2/3], Step [100/1200], Loss: 0.1178\n",
      "Epoch [2/3], Step [200/1200], Loss: 0.0404\n",
      "Epoch [2/3], Step [300/1200], Loss: 0.0454\n",
      "Epoch [2/3], Step [400/1200], Loss: 0.0160\n",
      "Epoch [2/3], Step [500/1200], Loss: 0.0284\n",
      "Epoch [2/3], Step [600/1200], Loss: 0.0657\n",
      "Epoch [2/3], Step [700/1200], Loss: 0.0251\n",
      "Epoch [2/3], Step [800/1200], Loss: 0.0363\n",
      "Epoch [2/3], Step [900/1200], Loss: 0.0557\n",
      "Epoch [2/3], Step [1000/1200], Loss: 0.0619\n",
      "Epoch [2/3], Step [1100/1200], Loss: 0.0409\n",
      "Epoch [2/3], Step [1200/1200], Loss: 0.0306\n",
      "Epoch [3/3], Step [100/1200], Loss: 0.0404\n",
      "Epoch [3/3], Step [200/1200], Loss: 0.0108\n",
      "Epoch [3/3], Step [300/1200], Loss: 0.0185\n",
      "Epoch [3/3], Step [400/1200], Loss: 0.0032\n",
      "Epoch [3/3], Step [500/1200], Loss: 0.0720\n",
      "Epoch [3/3], Step [600/1200], Loss: 0.0089\n",
      "Epoch [3/3], Step [700/1200], Loss: 0.0218\n",
      "Epoch [3/3], Step [800/1200], Loss: 0.0102\n",
      "Epoch [3/3], Step [900/1200], Loss: 0.0227\n",
      "Epoch [3/3], Step [1000/1200], Loss: 0.0037\n",
      "Epoch [3/3], Step [1100/1200], Loss: 0.0180\n",
      "Epoch [3/3], Step [1200/1200], Loss: 0.2510\n",
      "Settings: Batch Size: 50, Epochs: 3, Learning Rate: 0.001, Dropout Rate: 0.2, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/2], Step [100/600], Loss: 0.0868\n",
      "Epoch [1/2], Step [200/600], Loss: 0.1257\n",
      "Epoch [1/2], Step [300/600], Loss: 0.1340\n",
      "Epoch [1/2], Step [400/600], Loss: 0.1480\n",
      "Epoch [1/2], Step [500/600], Loss: 0.0458\n",
      "Epoch [1/2], Step [600/600], Loss: 0.0286\n",
      "Epoch [2/2], Step [100/600], Loss: 0.0491\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0549\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0764\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0847\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1234\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0118\n",
      "Settings: Batch Size: 100, Epochs: 2, Learning Rate: 0.01, Dropout Rate: 0.1, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/2], Step [100/600], Loss: 2.2966\n",
      "Epoch [1/2], Step [200/600], Loss: 2.2963\n",
      "Epoch [1/2], Step [300/600], Loss: 2.3018\n",
      "Epoch [1/2], Step [400/600], Loss: 2.3023\n",
      "Epoch [1/2], Step [500/600], Loss: 2.2987\n",
      "Epoch [1/2], Step [600/600], Loss: 2.3030\n",
      "Epoch [2/2], Step [100/600], Loss: 2.3144\n",
      "Epoch [2/2], Step [200/600], Loss: 2.2960\n",
      "Epoch [2/2], Step [300/600], Loss: 2.3022\n",
      "Epoch [2/2], Step [400/600], Loss: 2.3038\n",
      "Epoch [2/2], Step [500/600], Loss: 2.2983\n",
      "Epoch [2/2], Step [600/600], Loss: 2.2986\n",
      "Settings: Batch Size: 100, Epochs: 2, Learning Rate: 0.01, Dropout Rate: 0.1, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.10\n",
      "Epoch [1/2], Step [100/600], Loss: 0.2109\n",
      "Epoch [1/2], Step [200/600], Loss: 0.1665\n",
      "Epoch [1/2], Step [300/600], Loss: 0.2801\n",
      "Epoch [1/2], Step [400/600], Loss: 0.1726\n",
      "Epoch [1/2], Step [500/600], Loss: 0.0423\n",
      "Epoch [1/2], Step [600/600], Loss: 0.0227\n",
      "Epoch [2/2], Step [100/600], Loss: 0.2525\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0690\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0668\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0565\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1245\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0569\n",
      "Settings: Batch Size: 100, Epochs: 2, Learning Rate: 0.01, Dropout Rate: 0.2, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/2], Step [100/600], Loss: 0.6571\n",
      "Epoch [1/2], Step [200/600], Loss: 0.2544\n",
      "Epoch [1/2], Step [300/600], Loss: 0.2108\n",
      "Epoch [1/2], Step [400/600], Loss: 0.2494\n",
      "Epoch [1/2], Step [500/600], Loss: 0.3204\n",
      "Epoch [1/2], Step [600/600], Loss: 0.2716\n",
      "Epoch [2/2], Step [100/600], Loss: 0.2745\n",
      "Epoch [2/2], Step [200/600], Loss: 0.3346\n",
      "Epoch [2/2], Step [300/600], Loss: 0.1558\n",
      "Epoch [2/2], Step [400/600], Loss: 0.1743\n",
      "Epoch [2/2], Step [500/600], Loss: 0.1438\n",
      "Epoch [2/2], Step [600/600], Loss: 0.1706\n",
      "Settings: Batch Size: 100, Epochs: 2, Learning Rate: 0.01, Dropout Rate: 0.2, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.97\n",
      "Epoch [1/2], Step [100/600], Loss: 0.1873\n",
      "Epoch [1/2], Step [200/600], Loss: 0.0740\n",
      "Epoch [1/2], Step [300/600], Loss: 0.0699\n",
      "Epoch [1/2], Step [400/600], Loss: 0.1792\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1438\n",
      "Epoch [1/2], Step [600/600], Loss: 0.0671\n",
      "Epoch [2/2], Step [100/600], Loss: 0.0718\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0271\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0582\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0484\n",
      "Epoch [2/2], Step [500/600], Loss: 0.0673\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0699\n",
      "Settings: Batch Size: 100, Epochs: 2, Learning Rate: 0.001, Dropout Rate: 0.1, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.98\n",
      "Epoch [1/2], Step [100/600], Loss: 0.3355\n",
      "Epoch [1/2], Step [200/600], Loss: 0.1376\n",
      "Epoch [1/2], Step [300/600], Loss: 0.0934\n",
      "Epoch [1/2], Step [400/600], Loss: 0.0963\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1108\n",
      "Epoch [1/2], Step [600/600], Loss: 0.0687\n",
      "Epoch [2/2], Step [100/600], Loss: 0.0595\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0621\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0694\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0050\n",
      "Epoch [2/2], Step [500/600], Loss: 0.0227\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0492\n",
      "Settings: Batch Size: 100, Epochs: 2, Learning Rate: 0.001, Dropout Rate: 0.1, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/2], Step [100/600], Loss: 0.4439\n",
      "Epoch [1/2], Step [200/600], Loss: 0.2034\n",
      "Epoch [1/2], Step [300/600], Loss: 0.2035\n",
      "Epoch [1/2], Step [400/600], Loss: 0.1138\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1124\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1134\n",
      "Epoch [2/2], Step [100/600], Loss: 0.0495\n",
      "Epoch [2/2], Step [200/600], Loss: 0.1784\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0895\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0271\n",
      "Epoch [2/2], Step [500/600], Loss: 0.0856\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0844\n",
      "Settings: Batch Size: 100, Epochs: 2, Learning Rate: 0.001, Dropout Rate: 0.2, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/2], Step [100/600], Loss: 0.2319\n",
      "Epoch [1/2], Step [200/600], Loss: 0.1512\n",
      "Epoch [1/2], Step [300/600], Loss: 0.0722\n",
      "Epoch [1/2], Step [400/600], Loss: 0.1607\n",
      "Epoch [1/2], Step [500/600], Loss: 0.1926\n",
      "Epoch [1/2], Step [600/600], Loss: 0.1139\n",
      "Epoch [2/2], Step [100/600], Loss: 0.0395\n",
      "Epoch [2/2], Step [200/600], Loss: 0.0578\n",
      "Epoch [2/2], Step [300/600], Loss: 0.0991\n",
      "Epoch [2/2], Step [400/600], Loss: 0.0517\n",
      "Epoch [2/2], Step [500/600], Loss: 0.0612\n",
      "Epoch [2/2], Step [600/600], Loss: 0.0792\n",
      "Settings: Batch Size: 100, Epochs: 2, Learning Rate: 0.001, Dropout Rate: 0.2, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/3], Step [100/600], Loss: 0.0730\n",
      "Epoch [1/3], Step [200/600], Loss: 0.2386\n",
      "Epoch [1/3], Step [300/600], Loss: 0.2334\n",
      "Epoch [1/3], Step [400/600], Loss: 0.1660\n",
      "Epoch [1/3], Step [500/600], Loss: 0.1217\n",
      "Epoch [1/3], Step [600/600], Loss: 0.1041\n",
      "Epoch [2/3], Step [100/600], Loss: 0.0413\n",
      "Epoch [2/3], Step [200/600], Loss: 0.1004\n",
      "Epoch [2/3], Step [300/600], Loss: 0.1646\n",
      "Epoch [2/3], Step [400/600], Loss: 0.0509\n",
      "Epoch [2/3], Step [500/600], Loss: 0.1063\n",
      "Epoch [2/3], Step [600/600], Loss: 0.0633\n",
      "Epoch [3/3], Step [100/600], Loss: 0.0571\n",
      "Epoch [3/3], Step [200/600], Loss: 0.0353\n",
      "Epoch [3/3], Step [300/600], Loss: 0.1145\n",
      "Epoch [3/3], Step [400/600], Loss: 0.1169\n",
      "Epoch [3/3], Step [500/600], Loss: 0.0656\n",
      "Epoch [3/3], Step [600/600], Loss: 0.1190\n",
      "Settings: Batch Size: 100, Epochs: 3, Learning Rate: 0.01, Dropout Rate: 0.1, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.98\n",
      "Epoch [1/3], Step [100/600], Loss: 0.1985\n",
      "Epoch [1/3], Step [200/600], Loss: 0.1446\n",
      "Epoch [1/3], Step [300/600], Loss: 0.1420\n",
      "Epoch [1/3], Step [400/600], Loss: 0.1030\n",
      "Epoch [1/3], Step [500/600], Loss: 0.1235\n",
      "Epoch [1/3], Step [600/600], Loss: 0.1911\n",
      "Epoch [2/3], Step [100/600], Loss: 0.2130\n",
      "Epoch [2/3], Step [200/600], Loss: 0.1525\n",
      "Epoch [2/3], Step [300/600], Loss: 0.1246\n",
      "Epoch [2/3], Step [400/600], Loss: 0.1533\n",
      "Epoch [2/3], Step [500/600], Loss: 0.1939\n",
      "Epoch [2/3], Step [600/600], Loss: 0.1024\n",
      "Epoch [3/3], Step [100/600], Loss: 0.1038\n",
      "Epoch [3/3], Step [200/600], Loss: 0.0997\n",
      "Epoch [3/3], Step [300/600], Loss: 0.1004\n",
      "Epoch [3/3], Step [400/600], Loss: 0.1147\n",
      "Epoch [3/3], Step [500/600], Loss: 0.2490\n",
      "Epoch [3/3], Step [600/600], Loss: 0.0620\n",
      "Settings: Batch Size: 100, Epochs: 3, Learning Rate: 0.01, Dropout Rate: 0.1, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.98\n",
      "Epoch [1/3], Step [100/600], Loss: 0.1133\n",
      "Epoch [1/3], Step [200/600], Loss: 0.2388\n",
      "Epoch [1/3], Step [300/600], Loss: 0.1829\n",
      "Epoch [1/3], Step [400/600], Loss: 0.0867\n",
      "Epoch [1/3], Step [500/600], Loss: 0.0825\n",
      "Epoch [1/3], Step [600/600], Loss: 0.0482\n",
      "Epoch [2/3], Step [100/600], Loss: 0.0988\n",
      "Epoch [2/3], Step [200/600], Loss: 0.0439\n",
      "Epoch [2/3], Step [300/600], Loss: 0.0576\n",
      "Epoch [2/3], Step [400/600], Loss: 0.0627\n",
      "Epoch [2/3], Step [500/600], Loss: 0.1474\n",
      "Epoch [2/3], Step [600/600], Loss: 0.0654\n",
      "Epoch [3/3], Step [100/600], Loss: 0.0682\n",
      "Epoch [3/3], Step [200/600], Loss: 0.0141\n",
      "Epoch [3/3], Step [300/600], Loss: 0.0299\n",
      "Epoch [3/3], Step [400/600], Loss: 0.1811\n",
      "Epoch [3/3], Step [500/600], Loss: 0.0753\n",
      "Epoch [3/3], Step [600/600], Loss: 0.0631\n",
      "Settings: Batch Size: 100, Epochs: 3, Learning Rate: 0.01, Dropout Rate: 0.2, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/3], Step [100/600], Loss: 0.3611\n",
      "Epoch [1/3], Step [200/600], Loss: 0.2373\n",
      "Epoch [1/3], Step [300/600], Loss: 0.1796\n",
      "Epoch [1/3], Step [400/600], Loss: 0.1739\n",
      "Epoch [1/3], Step [500/600], Loss: 0.1323\n",
      "Epoch [1/3], Step [600/600], Loss: 0.2207\n",
      "Epoch [2/3], Step [100/600], Loss: 0.1556\n",
      "Epoch [2/3], Step [200/600], Loss: 0.2751\n",
      "Epoch [2/3], Step [300/600], Loss: 0.3497\n",
      "Epoch [2/3], Step [400/600], Loss: 0.3257\n",
      "Epoch [2/3], Step [500/600], Loss: 0.2167\n",
      "Epoch [2/3], Step [600/600], Loss: 0.3114\n",
      "Epoch [3/3], Step [100/600], Loss: 0.1348\n",
      "Epoch [3/3], Step [200/600], Loss: 0.4000\n",
      "Epoch [3/3], Step [300/600], Loss: 0.3393\n",
      "Epoch [3/3], Step [400/600], Loss: 0.1182\n",
      "Epoch [3/3], Step [500/600], Loss: 0.4672\n",
      "Epoch [3/3], Step [600/600], Loss: 0.1517\n",
      "Settings: Batch Size: 100, Epochs: 3, Learning Rate: 0.01, Dropout Rate: 0.2, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.98\n",
      "Epoch [1/3], Step [100/600], Loss: 0.3189\n",
      "Epoch [1/3], Step [200/600], Loss: 0.1449\n",
      "Epoch [1/3], Step [300/600], Loss: 0.3057\n",
      "Epoch [1/3], Step [400/600], Loss: 0.0511\n",
      "Epoch [1/3], Step [500/600], Loss: 0.0370\n",
      "Epoch [1/3], Step [600/600], Loss: 0.1105\n",
      "Epoch [2/3], Step [100/600], Loss: 0.0299\n",
      "Epoch [2/3], Step [200/600], Loss: 0.0265\n",
      "Epoch [2/3], Step [300/600], Loss: 0.0217\n",
      "Epoch [2/3], Step [400/600], Loss: 0.0493\n",
      "Epoch [2/3], Step [500/600], Loss: 0.1174\n",
      "Epoch [2/3], Step [600/600], Loss: 0.0967\n",
      "Epoch [3/3], Step [100/600], Loss: 0.0809\n",
      "Epoch [3/3], Step [200/600], Loss: 0.0115\n",
      "Epoch [3/3], Step [300/600], Loss: 0.0235\n",
      "Epoch [3/3], Step [400/600], Loss: 0.0530\n",
      "Epoch [3/3], Step [500/600], Loss: 0.0105\n",
      "Epoch [3/3], Step [600/600], Loss: 0.0341\n",
      "Settings: Batch Size: 100, Epochs: 3, Learning Rate: 0.001, Dropout Rate: 0.1, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/3], Step [100/600], Loss: 0.2606\n",
      "Epoch [1/3], Step [200/600], Loss: 0.1362\n",
      "Epoch [1/3], Step [300/600], Loss: 0.1308\n",
      "Epoch [1/3], Step [400/600], Loss: 0.0726\n",
      "Epoch [1/3], Step [500/600], Loss: 0.1237\n",
      "Epoch [1/3], Step [600/600], Loss: 0.0288\n",
      "Epoch [2/3], Step [100/600], Loss: 0.0442\n",
      "Epoch [2/3], Step [200/600], Loss: 0.0362\n",
      "Epoch [2/3], Step [300/600], Loss: 0.0480\n",
      "Epoch [2/3], Step [400/600], Loss: 0.0160\n",
      "Epoch [2/3], Step [500/600], Loss: 0.0454\n",
      "Epoch [2/3], Step [600/600], Loss: 0.0498\n",
      "Epoch [3/3], Step [100/600], Loss: 0.1119\n",
      "Epoch [3/3], Step [200/600], Loss: 0.0256\n",
      "Epoch [3/3], Step [300/600], Loss: 0.0370\n",
      "Epoch [3/3], Step [400/600], Loss: 0.0157\n",
      "Epoch [3/3], Step [500/600], Loss: 0.0298\n",
      "Epoch [3/3], Step [600/600], Loss: 0.0374\n",
      "Settings: Batch Size: 100, Epochs: 3, Learning Rate: 0.001, Dropout Rate: 0.1, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/3], Step [100/600], Loss: 0.4109\n",
      "Epoch [1/3], Step [200/600], Loss: 0.1455\n",
      "Epoch [1/3], Step [300/600], Loss: 0.1742\n",
      "Epoch [1/3], Step [400/600], Loss: 0.1091\n",
      "Epoch [1/3], Step [500/600], Loss: 0.0816\n",
      "Epoch [1/3], Step [600/600], Loss: 0.0747\n",
      "Epoch [2/3], Step [100/600], Loss: 0.1219\n",
      "Epoch [2/3], Step [200/600], Loss: 0.1041\n",
      "Epoch [2/3], Step [300/600], Loss: 0.0905\n",
      "Epoch [2/3], Step [400/600], Loss: 0.0450\n",
      "Epoch [2/3], Step [500/600], Loss: 0.0292\n",
      "Epoch [2/3], Step [600/600], Loss: 0.1289\n",
      "Epoch [3/3], Step [100/600], Loss: 0.0996\n",
      "Epoch [3/3], Step [200/600], Loss: 0.0424\n",
      "Epoch [3/3], Step [300/600], Loss: 0.0323\n",
      "Epoch [3/3], Step [400/600], Loss: 0.0706\n",
      "Epoch [3/3], Step [500/600], Loss: 0.0548\n",
      "Epoch [3/3], Step [600/600], Loss: 0.0603\n",
      "Settings: Batch Size: 100, Epochs: 3, Learning Rate: 0.001, Dropout Rate: 0.2, Layers: 2\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n",
      "Epoch [1/3], Step [100/600], Loss: 0.1782\n",
      "Epoch [1/3], Step [200/600], Loss: 0.2653\n",
      "Epoch [1/3], Step [300/600], Loss: 0.1213\n",
      "Epoch [1/3], Step [400/600], Loss: 0.1464\n",
      "Epoch [1/3], Step [500/600], Loss: 0.0818\n",
      "Epoch [1/3], Step [600/600], Loss: 0.0685\n",
      "Epoch [2/3], Step [100/600], Loss: 0.1165\n",
      "Epoch [2/3], Step [200/600], Loss: 0.0551\n",
      "Epoch [2/3], Step [300/600], Loss: 0.0189\n",
      "Epoch [2/3], Step [400/600], Loss: 0.0664\n",
      "Epoch [2/3], Step [500/600], Loss: 0.0475\n",
      "Epoch [2/3], Step [600/600], Loss: 0.0626\n",
      "Epoch [3/3], Step [100/600], Loss: 0.0211\n",
      "Epoch [3/3], Step [200/600], Loss: 0.0646\n",
      "Epoch [3/3], Step [300/600], Loss: 0.0383\n",
      "Epoch [3/3], Step [400/600], Loss: 0.0641\n",
      "Epoch [3/3], Step [500/600], Loss: 0.0128\n",
      "Epoch [3/3], Step [600/600], Loss: 0.0456\n",
      "Settings: Batch Size: 100, Epochs: 3, Learning Rate: 0.001, Dropout Rate: 0.2, Layers: 3\n",
      "Test Accuracy of the model on the 10000 test images: 0.99\n"
     ]
    }
   ],
   "source": [
    "# This will take long time to run, so you can run in chunks, with secific set of parameters if you like\n",
    "batch_sizes = [50, 100]\n",
    "epochs = [2, 3]\n",
    "learning_rates = [0.01, 0.001]\n",
    "dropout_rates = [0.1, 0.2]\n",
    "num_layers_list = [2, 3]\n",
    "\n",
    "results = run_experiment(batch_sizes, epochs, learning_rates, dropout_rates, num_layers_list)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d345e0c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(50, 2, 0.01, 0.1, 2, 0.9771),\n",
       " (50, 2, 0.01, 0.1, 3, 0.9618),\n",
       " (50, 2, 0.01, 0.2, 2, 0.9775),\n",
       " (50, 2, 0.01, 0.2, 3, 0.1135),\n",
       " (50, 2, 0.001, 0.1, 2, 0.9867),\n",
       " (50, 2, 0.001, 0.1, 3, 0.9861),\n",
       " (50, 2, 0.001, 0.2, 2, 0.9878),\n",
       " (50, 2, 0.001, 0.2, 3, 0.9907),\n",
       " (50, 3, 0.01, 0.1, 2, 0.9824),\n",
       " (50, 3, 0.01, 0.1, 3, 0.1135),\n",
       " (50, 3, 0.01, 0.2, 2, 0.981),\n",
       " (50, 3, 0.01, 0.2, 3, 0.1135),\n",
       " (50, 3, 0.001, 0.1, 2, 0.9886),\n",
       " (50, 3, 0.001, 0.1, 3, 0.989),\n",
       " (50, 3, 0.001, 0.2, 2, 0.986),\n",
       " (50, 3, 0.001, 0.2, 3, 0.9905),\n",
       " (100, 2, 0.01, 0.1, 2, 0.9872),\n",
       " (100, 2, 0.01, 0.1, 3, 0.098),\n",
       " (100, 2, 0.01, 0.2, 2, 0.9851),\n",
       " (100, 2, 0.01, 0.2, 3, 0.9707),\n",
       " (100, 2, 0.001, 0.1, 2, 0.9848),\n",
       " (100, 2, 0.001, 0.1, 3, 0.9873),\n",
       " (100, 2, 0.001, 0.2, 2, 0.9853),\n",
       " (100, 2, 0.001, 0.2, 3, 0.9871),\n",
       " (100, 3, 0.01, 0.1, 2, 0.9782),\n",
       " (100, 3, 0.01, 0.1, 3, 0.98),\n",
       " (100, 3, 0.01, 0.2, 2, 0.9859),\n",
       " (100, 3, 0.01, 0.2, 3, 0.9794),\n",
       " (100, 3, 0.001, 0.1, 2, 0.9852),\n",
       " (100, 3, 0.001, 0.1, 3, 0.99),\n",
       " (100, 3, 0.001, 0.2, 2, 0.9861),\n",
       " (100, 3, 0.001, 0.2, 3, 0.9905)]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "1189220b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1000x800 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_results(results)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8db168c7",
   "metadata": {},
   "source": [
    "## CNN Architecture Shape Transformation\n",
    "\n",
    "### Input\n",
    "- **Shape:** `1x28x28`\n",
    "\n",
    "### Conv1\n",
    "- **Operation:** Convolution with `16 filters`, `5x5`, `stride=1`, `padding=2`\n",
    "- **Shape after Conv1:** `16x28x28`\n",
    "- **Operation:** Max Pooling with `kernel size=2`, `stride=2`\n",
    "- **Shape after MaxPool1:** `16x14x14`\n",
    "\n",
    "### Conv2\n",
    "- **Operation:** Convolution with `32 filters`, `5x5`, `stride=1`, `padding=2`\n",
    "- **Shape after Conv2:** `32x14x14`\n",
    "- **Operation:** Max Pooling with `kernel size=2`, `stride=2`\n",
    "- **Shape after MaxPool2:** `32x7x7`\n",
    "\n",
    "### Conv3\n",
    "- **Operation:** Convolution with `64 filters`, `5x5`, `stride=1`, `padding=2`\n",
    "- **Shape after Conv3:** `64x7x7`\n",
    "- **Operation:** Max Pooling with `kernel size=2`, `stride=2`\n",
    "- **Shape after MaxPool3:** `64x3x3`\n",
    "\n",
    "### Fully Connected Layer\n",
    "- **Operation:** Flatten\n",
    "- **Shape before FC:** `64x3x3` (flattened to `576`)\n",
    "- **Operation:** Linear transformation to `10 classes`\n",
    "- **Output Shape:** `10`\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a38dde60",
   "metadata": {},
   "outputs": [],
   "source": [
    "# w_out = (w_in - F +2p) /s + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eadd582f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
